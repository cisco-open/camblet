---
title: 'Try with Kubernetes'
description: 'Your first zero trust Kubernetes environment'
---

import { Tabs, TabItem } from '@astrojs/starlight/components';

This guide will walk you through how Camblet can be used with Kubernetes.
We are going to use a one node Kubernetes environment with a simple curl client pod and an echo server deployment.

### Prerequisites

> This guide assumes the existance of a Lima instance with K3s called `quickstart` with Camblet installed.
> It can be created following the [installation guide](/docs/start/installation).
> The Lima instance must be created with the K3s template for this guide to work!

### Enter into the Lima VM

```sh
limactl shell quickstart
```

### Configure Camblet agent

Configure the agent to access Kubernetes metadata.
This data comes from the kubelet, so the proper certificates and keys must be provided to the agent.
Copy the keys and certificates used by k3s to the Camblet directory:

```sh
sudo cp /var/lib/rancher/k3s/server/tls/client-admin.key /etc/camblet/kubelet-client.key
sudo cp /var/lib/rancher/k3s/server/tls/client-admin.crt /etc/camblet/kubelet-client.crt
sudo cp /var/lib/rancher/k3s/server/tls/server-ca.crt /etc/camblet/kubelet-ca.crt 
sudo chmod 644 /etc/camblet/kubelet-client.key
sudo chmod 644 /etc/camblet/kubelet-client.crt
sudo chmod 644 /etc/camblet/kubelet-ca.crt
```

The agent configuration resides in /etc/camblet/config.yaml, modify it the enable the Kubernetes metadata collector.

Add the following to the config under `agent.metadataCollectors`:

```yaml
kubernetes:
  enabled: true
  kubeletCA: /etc/camblet/kubelet-ca.crt
  credentials: /etc/camblet/kubelet-client.crt,/etc/camblet/kubelet-client.key
```

The config should resemble the following:

```sh
agent:
  trustDomain: acme.corp
  defaultCertTTL: 2h
  metadataCollectors:
    procfs:
      enabled: true
      extractEnvs: false
    linuxos:
      enabled: true
    sysfsdmi:
      enabled: true
    azure:
      enabled: false
    ec2:
      enabled: false
    gcp:
      enabled: false
    kubernetes:
      enabled: true
      kubeletCA: /etc/camblet/kubelet-ca.crt
      credentials: /etc/camblet/kubelet-client.crt,/etc/camblet/kubelet-client.key
    docker:
      enabled: false
```

The Camblet agent must be restarted after the configuration change.

```sh
sudo systemctl restart camblet.service
```

Let's check if the agent is indeed able to collect metadata from Kubernetes for a process that runs within a pod.
K3s comes with Traefik installed so the following command can be used as a test.

```sh
$ camblet agent augment $(pidof traefik)
k8s:annotation:kubernetes.io/config.seen:2024-01-26T14:56:05.047670838Z
k8s:annotation:kubernetes.io/config.source:api
k8s:annotation:prometheus.io/path:/metrics
k8s:annotation:prometheus.io/port:9100
k8s:annotation:prometheus.io/scrape:true
k8s:container:image:id:docker.io/rancher/mirrored-library-traefik@sha256:ca9c8fbe001070c546a75184e3fd7f08c3e47dfc1e89bff6fe2edd302accfaec
k8s:container:name:traefik
k8s:label:app.kubernetes.io/instance:traefik-kube-system
k8s:label:app.kubernetes.io/managed-by:Helm
k8s:label:app.kubernetes.io/name:traefik
k8s:label:helm.sh/chart:traefik-25.0.2_up25.0.0
k8s:label:pod-template-hash:f4564c4f4
k8s:node:name:lima-quickstart
k8s:pod:ephemeral-image:count:0
k8s:pod:image:count:1
k8s:pod:image:id:docker.io/rancher/mirrored-library-traefik@sha256:ca9c8fbe001070c546a75184e3fd7f08c3e47dfc1e89bff6fe2edd302accfaec
k8s:pod:image:name:rancher/mirrored-library-traefik:2.10.5
k8s:pod:init-image:count:0
k8s:pod:name:traefik-f4564c4f4-fqhqm
k8s:pod:namespace:kube-system
k8s:pod:owner:kind:replicaset
k8s:pod:owner:kind-with-version:apps/v1/replicaset
k8s:pod:serviceaccount:traefik
...
```

Upon successful Camblet re-configuration, Kubernetes-associated labels can be utilized for process identification as well.

### Deploy workloads to Kubernetes

An echo server running as a Kubernetes deployment and a simple Alpine pod with cURL are going to be used to showcase how Camblet integrates with Kubernetes.

First, install the echo server using kubectl:

```sh
kubectl create -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo
  labels:
    k8s-app: echo
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: echo
  template:
    metadata:
      labels:
        k8s-app: echo
    spec:
      terminationGracePeriodSeconds: 2
      containers:
      - name: echo-service
        image: ghcr.io/cisco-open/nasp-echo-server:main
        ports:
        - containerPort: 8080
        resources:
          limits:
            cpu: 1000m
            memory: 128Mi
          requests:
            cpu: 500m
            memory: 64Mi
---
apiVersion: v1
kind: Service
metadata:
  name: echo
  labels:
    k8s-app: echo
spec:
  ports:
  - name: http
    port: 80
    targetPort: 8080
  selector:
    k8s-app: echo
EOF

```

Let's wait for the echo pod to be up and running.

```sh
kubectl wait --for=condition=ready pod -l k8s-app=echo
```

Now create a simple Alpine pod which will host our cURL client.

```sh
kubectl create -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: alpine
spec:
  containers:
  - name: alpine
    image: alpine
    # Just spin & wait forever
    command: [ "/bin/sh", "-c", "--" ]
    args: [ "while true; do sleep 3000; done;" ]
EOF
```

Let's wait for the alpine pod to come up.

```sh
kubectl wait --for=condition=ready pod alpine
```

### Create policy for the echo server

It is time to assign strong identities to the workloads and transparently establish mTLS connections.

The [policy](/docs/concepts/policy) can be written by hand, but the Camblet CLI can do the work for you with the `generate-policy` command. There are two mandatory parameters, the PID of the process and the workload ID.

```sh
camblet agent generate-policy $(pidof server) echo-server | sudo tee /etc/camblet/policies/echo-server.yaml
```

The output should be similar:

```yaml
- certificate:
    ttl: 86400s
    workloadID: echo-server
  connection:
    mtls: STRICT
  selectors:
  - k8s:container:name: echo-service
    k8s:pod:name: echo-54c896dd86-tnvpq
    k8s:pod:namespace: default
    k8s:pod:serviceaccount: default
    process:binary:path: /server
    process:gid: "65532"
    process:name: server
    process:uid: "65532"
```

> The saved policy file is automatically read by the running Camblet agent and gets updated within the kernel.

Camblet will use these selectors to identify the echo server. In a well-written policy the selectors should describe a particular process as precisely as possible, there are various [metadata collectors](/docs/concepts/process-metadata) available to achieve that goal. The `connection` part configures the TLS settings where `STRICT` mTLS value means only clients with trusted certificates can communicate with it.

#### To verify that, let's try it with cURL from the Alpine container

```sh
kubectl exec -it alpine sh
```

Inside the Alpine container, first, we have to install cURL:

```sh
apk add curl
```

Next, try to connect to the echo server on echo:

```sh
curl echo
```

> A second try could be necessary to achive the wanted effect!

The output should be similar:

```sh
curl: (56) Recv failure: Connection reset by peer
```

The connection failed, as it was supposed to. Since Camblet now protects the echo-server workload with mTLS nothing can communicate with it without a trusted client certificate.

Now exit from the Alpine container and let's create a policy for cURL as well. A running process of cURL is the easiest way to create a new policy for cURL with the Camblet CLI. Since cURL is not running continuously like the server, a "dummy" command is needed to force it to run until generate the policy.

The following command will run a cURL process for 30 seconds, the 1.2.3.4 IP address is non-routed and the connection to it going to time out. This is plenty of time to generate the policy.

```sh
kubectl exec alpine -- sh -c "curl --connect-timeout 30 1.2.3.4 >/dev/null 2>&1 &"
```

Let's generate a policy for cURL

```sh
camblet --config /etc/camblet/config.yaml agent generate-policy $(pidof curl) curl | sudo tee /etc/camblet/policies/curl.yaml
```

The output should be similar:

```yaml
- certificate:
    ttl: 86400s
    workloadID: curl
  connection:
    mtls: STRICT
  selectors:
  - k8s:container:name: alpine
    k8s:pod:name: alpine
    k8s:pod:namespace: default
    k8s:pod:serviceaccount: default
    process:binary:path: /usr/bin/curl
    process:gid: "0"
    process:name: curl
    process:uid: "0"
```

Using this policy, cURL gets an identity and will use mTLS. Let's try to communicate with the nginx once again.

### Try to connect to the echo server with certificate

```sh
$ kubectl exec -it alpine -- curl echo
curl: (56) Recv failure: Connection reset by peer
```

It still doesn't work, one last piece of the puzzle is missing. Camblet must ascertain the target destination for the application of policies.
Enforcing policies on every egress connection implies that cURL won't be able to reach destinations beyond the Camblet-managed environment.
Services has to be registered into the [service registry](/docs/concepts/service-registry) through service definitions.

**Sample Service discovery configuration file**

```sh
- addresses:
  - address: localhost
    port: 80
  labels:
    app:label: app
```

Let's ignore the labels part for now; it is meant for more advanced configuration.
The `addresses` section specifies the registered destination addresses to which the policies should be applied.

Let's create a service registry entry for the echo-server service with the following command:

```sh
SVC_IP=$(kubectl get svc echo -o jsonpath='{@.spec.clusterIP}')
envsubst <<EOF | sudo tee /etc/camblet/services/echo-service.yaml >/dev/null
- addresses:
  - address: $SVC_IP
    port: 80
  labels:
    app:label: echo-server
EOF
```

### Try to connect to the echo server with certificate and configured Camblet

With the service registry entry for the echo-server service in place, let's check if its indeed fixed the error.
To do that, execute once again into the Alpine container and run cURL.

```sh
kubectl exec -it alpine -- curl echo
```

> A second try could be necessary to achive the wanted effect!

The output should be similar:

```sh
Hostname: echo-54c896dd86-x9tdj

Pod Information:
  -no pod information available-

Request Information:
  client_address=10.42.0.23:55956
  method=GET
  real path=/
  query=
  request_version=1.1
  request_scheme=http
  request_url=http://echo/

Request Headers:
  accept=*/*
  user-agent=curl/8.5.0

Request Body:
```

It finally works.

### Cleanup

Exit from the Lima VM and delete it to cleanup.

```sh
limactl delete quickstart --force
```
